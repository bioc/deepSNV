#' Shearwater ML
#' 
#' This is shearwater generating P-values
#'
#' @param counts The array of counts typically generated by loadAllData.
#' @param rho A number
#' @param truncate
#' @param rho.min
#' @return rho.max
#' @examples
#' # code to be added
#' @export
#' @author Inigo Martincorena
pvals_betabinLRT = function (counts, rho = NULL, truncate = 0.01, rho.min = 1e-04, rho.max = 0.8) {
  
  snp_and_ref_filter = 0.1 # Sites where the current nt accounts for more than 30% of the reads are not tested for (reference nt or SNPs)
  min_local_coverage = 20 # Sites with lower local coverage are not tested for
  
  method = "CombinedLRT" # Combined LRT with both strands in the sample having the same mutation rate (errors are negligible)
  #method = "Fisher" # Separate p-value per strand + Fisher combined p-value
  #method = "Sum" # Separate p-value per strand + Sum combined p-value
  
  
  # deepSNV functions
  estimateRho = deepSNV:::estimateRho
  logbb = deepSNV:::logbb
  
  
  pseudo = .Machine$double.eps
  ncol = dim(counts)[3]/2
  x.fw = counts[, , 1:ncol]
  x.bw = counts[, , 1:ncol + ncol]
  n.fw = rep(rowSums(x.fw, dims = 2), dim(x.fw)[3])
  n.bw = rep(rowSums(x.bw, dims = 2), dim(x.bw)[3])
  dim(n.fw) = dim(x.fw)
  dim(n.bw) = dim(x.bw)
  
  x = x.fw + x.bw
  n = n.fw + n.bw
  mu = pmax(x,pseudo)/pmax(n,pseudo)
  
  ix = (mu < truncate)
  
  # Calculation of rho
  if (is.null(rho)) {
    rho = estimateRho(x, mu, ix)
    rho = pmin(pmax(rho, rho.min), rho.max)
    rho[is.na(rho)] = rho.min
  }
  disp = (1 - rho)/rho
  rdisp = rep(disp, each = nrow(counts))
  mu = mu * rdisp
  
  tr.fw = x.fw * ix
  tr.bw = x.bw * ix
  
  X.fw = rep(colSums(tr.fw, dims = 1), each = nrow(counts)) - tr.fw
  N.fw = rep(colSums(n.fw * ix), each = nrow(counts)) - n.fw * ix
  
  X.bw = rep(colSums(tr.bw, dims = 1), each = nrow(counts)) - tr.bw
  N.bw = rep(colSums(n.bw * ix), each = nrow(counts)) - n.bw * ix
  
  prob0.fw = (X.fw + x.fw)/(N.fw + n.fw); prob0.fw[prob0.fw==0] = pseudo
  prob1s.fw = x.fw/(n.fw+pseudo); prob1s.fw[prob1s.fw==0] = pseudo
  prob1c.fw = X.fw/(N.fw+pseudo); prob1c.fw[prob1c.fw==0] = pseudo
  prob1s.fw = pmax(prob1s.fw,prob1c.fw) # Min error rate is that of the population (one-sided test)
  nu0.fw = prob0.fw * rdisp; nu1s.fw = prob1s.fw * rdisp; nu1c.fw = prob1c.fw * rdisp; 
  
  prob0.bw = (X.bw + x.bw)/(N.bw + n.bw); prob0.bw[prob0.bw==0] = pseudo
  prob1s.bw = x.bw/(n.bw+pseudo); prob1s.bw[prob1s.bw==0] = pseudo
  prob1c.bw = X.bw/(N.bw+pseudo); prob1c.bw[prob1c.bw==0] = pseudo
  prob1s.bw = pmax(prob1s.bw,prob1c.bw) # Min error rate is that of the population (one-sided test)
  nu0.bw = prob0.bw * rdisp; nu1s.bw = prob1s.bw * rdisp; nu1c.bw = prob1c.bw * rdisp; 
  
  # Note: The notation here is different from Moritz's: nu0=nu0, nu1s=mu0, nu1c=nu
  
  
  # Beta-Binomial LRT
  if (method %in% c("Fisher","Sum")) {
    # Likelihood-Ratio tests
    LL.fw = logbb(x.fw, n.fw, nu0.fw, rdisp) + logbb(X.fw, N.fw, nu0.fw, rdisp) - logbb(x.fw, n.fw, nu1s.fw, rdisp) - logbb(X.fw, N.fw, nu1c.fw, rdisp)
    pvals_fw = pchisq(-2*LL.fw, df=2, lower.tail=F)/2 # We divide by 2 as we are performing a 1-sided test
    
    LL.bw = logbb(x.bw, n.bw, nu0.bw, rdisp) + logbb(X.bw, N.bw, nu0.bw, rdisp) - logbb(x.bw, n.bw, nu1s.bw, rdisp) - logbb(X.bw, N.bw, nu1c.bw, rdisp)
    pvals_bw = pchisq(-2*LL.bw, df=2, lower.tail=F)/2 # We divide by 2 as we are performing a 1-sided test
    
    if (method=="Fisher") { 
      # Fisher's combined p-value
      pvals_both = pchisq(-2*(log(pvals_fw)+log(pvals_bw)),4,low=F)
      
    } else { 
      # Sum combined p-value
      ptriangle = function(x) ifelse(x<0.5, 2*x^2, 1-2*(1-x)^2)
      pvals_both = ptriangle(0.5*(pvals_fw + pvals_bw))
      qvals = p.adjust(pvals_both, method="BH")
      dim(qvals) = dim(pvals_both)
    }
    
  } else if (method=="CombinedLRT") {
    
    # Alternatively, both strands have to have the same mutation rate in the sample in H1
    prob1s.both = (x.fw+x.bw)/(n.fw+n.bw+pseudo); prob1s.both[prob1s.both==0] = pseudo
    prob1s.both = pmax(prob1s.both,pmax(prob1c.fw,prob1c.bw)) # Min error rate is that of the population (one-sided test)
    nu1s.both = prob1s.both * rdisp
    
    LL.both = logbb(x.fw, n.fw, nu0.fw, rdisp) + logbb(X.fw, N.fw, nu0.fw, rdisp) + logbb(x.bw, n.bw, nu0.bw, rdisp) + logbb(X.bw, N.bw, nu0.bw, rdisp) - logbb(x.fw, n.fw, nu1s.both, rdisp) - logbb(X.fw, N.fw, nu1c.fw, rdisp) - logbb(x.bw, n.bw, nu1s.both, rdisp) - logbb(X.bw, N.bw, nu1c.bw, rdisp) 
    
    #LL.both = dbetabinom(x.fw, n.fw, prob0.fw, rho, log=T) + dbetabinom(X.fw, N.fw, prob0.fw, rho, log=T) + dbetabinom(x.bw, n.bw, prob0.bw, rho, log=T) + dbetabinom(X.bw, N.bw, prob0.bw, rho, log=T) - dbetabinom(x.fw, n.fw, prob1s.both, rho, log=T) - dbetabinom(X.fw, N.fw, prob1c.fw, rho, log=T) - dbetabinom(x.bw, n.bw, prob1s.both, rho, log=T) - dbetabinom(X.bw, N.bw, prob1c.bw, rho, log=T)
    
    pvals_both = pchisq(-2*LL.both, df=2, lower.tail=F)/2 # We divide by 2 as we are performing a 1-sided test
    
  }        
  
  # Masking out undesired tests (it boosts power)
  pvals_both[(n.fw+n.bw)<min_local_coverage] = NA
  pvals_both[(prob0.bw>snp_and_ref_filter) & (prob0.fw>snp_and_ref_filter)] = NA
  
  qvals = p.adjust(pvals_both, method="BH")
  dim(qvals) = dim(pvals_both)
  #sum(qvals<0.05,na.rm=T)
  
  return(pvals_both)
}







